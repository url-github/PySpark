{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iVwwf7ZZ9dE",
        "outputId": "1de9785c-9396-4e3c-e151-7b24c786e950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=7952f065367ed0bbc457287b6427a658ee82644ca223a7821bea4f028512e7c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "FG1tzdbGaEqH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "7P7tCRgmaNGf",
        "outputId": "b386154c-6286-4f3f-a815-ccdb38ec9f16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bf06f794e80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://68067c11d7e6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arrayData = [\n",
        "        ('Bob',['New York','Boston']),\n",
        "        ('Kim',['Los Angeles','Chicago',None]),\n",
        "        ('Lee',['Phoenix','']),\n",
        "        ('Peter',None),\n",
        "        ('Sam',['San Diego','Dallas'])]\n",
        "\n",
        "col = ['name','location']"
      ],
      "metadata": {
        "id": "bDq-QeVDaUxH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=arrayData, schema=col)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7t12CNBanfg",
        "outputId": "3f40b7b6-b946-4510-8aa5-9e5d1ee0d0ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- location: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-----+--------------------+\n",
            "| name|            location|\n",
            "+-----+--------------------+\n",
            "|  Bob|  [New York, Boston]|\n",
            "|  Kim|[Los Angeles, Chi...|\n",
            "|  Lee|         [Phoenix, ]|\n",
            "|Peter|                NULL|\n",
            "|  Sam| [San Diego, Dallas]|\n",
            "+-----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df2 = df.select(df.name,explode(df.location))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBinb9Yba0Oq",
        "outputId": "80afa4cc-1b20-44d4-9b09-537ed82d397b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+----+-----------+\n",
            "|name|        col|\n",
            "+----+-----------+\n",
            "| Bob|   New York|\n",
            "| Bob|     Boston|\n",
            "| Kim|Los Angeles|\n",
            "| Kim|    Chicago|\n",
            "| Kim|       NULL|\n",
            "| Lee|    Phoenix|\n",
            "| Lee|           |\n",
            "| Sam|  San Diego|\n",
            "| Sam|     Dallas|\n",
            "+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`posexplode()` dodatkowo zwraca indeks (pozycję elementu) w danym zbiorze danych, czyli dla każdej wartości wyciągniętej z tablicy (lub innej kolekcji), oprócz wartości, zwraca także jej pozycję (indeks)."
      ],
      "metadata": {
        "id": "2hjPDopGcJQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import posexplode\n",
        "df2 = df.select(df.name,posexplode(df.location))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVOvHTfnbOdD",
        "outputId": "8b949c65-eb48-4380-8cc8-86031978ac84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- pos: integer (nullable = false)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+----+---+-----------+\n",
            "|name|pos|        col|\n",
            "+----+---+-----------+\n",
            "| Bob|  0|   New York|\n",
            "| Bob|  1|     Boston|\n",
            "| Kim|  0|Los Angeles|\n",
            "| Kim|  1|    Chicago|\n",
            "| Kim|  2|       NULL|\n",
            "| Lee|  0|    Phoenix|\n",
            "| Lee|  1|           |\n",
            "| Sam|  0|  San Diego|\n",
            "| Sam|  1|     Dallas|\n",
            "+----+---+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "W przeciwieństwie do `explode()`, która ignoruje wartości null i puste tablice, `explode_outer()` zachowuje te wartości, zamieniając null na wiersze z wartością null."
      ],
      "metadata": {
        "id": "YmyAoT0tcqyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode_outer\n",
        "df2 = df.select(df.name,explode_outer(df.location))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMQno03vbszL",
        "outputId": "855fb560-d487-4c00-d14d-03ae4ec24050"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+-----+-----------+\n",
            "| name|        col|\n",
            "+-----+-----------+\n",
            "|  Bob|   New York|\n",
            "|  Bob|     Boston|\n",
            "|  Kim|Los Angeles|\n",
            "|  Kim|    Chicago|\n",
            "|  Kim|       NULL|\n",
            "|  Lee|    Phoenix|\n",
            "|  Lee|           |\n",
            "|Peter|       NULL|\n",
            "|  Sam|  San Diego|\n",
            "|  Sam|     Dallas|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import posexplode_outer\n",
        "df2 = df.select(df.name,posexplode_outer(df.location))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwNEOltDcvKX",
        "outputId": "869e3afc-8297-4497-f6ff-6fd647eb7300"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- pos: integer (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+-----+----+-----------+\n",
            "| name| pos|        col|\n",
            "+-----+----+-----------+\n",
            "|  Bob|   0|   New York|\n",
            "|  Bob|   1|     Boston|\n",
            "|  Kim|   0|Los Angeles|\n",
            "|  Kim|   1|    Chicago|\n",
            "|  Kim|   2|       NULL|\n",
            "|  Lee|   0|    Phoenix|\n",
            "|  Lee|   1|           |\n",
            "|Peter|NULL|       NULL|\n",
            "|  Sam|   0|  San Diego|\n",
            "|  Sam|   1|     Dallas|\n",
            "+-----+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapData = [\n",
        "        ('Bob',{'cuisine':'Chinese','color':'blue'}),\n",
        "        ('Kim',{'cuisine':'Indian','color':None}),\n",
        "        ('Lee',{'cuisine':'Japanese','color':''}),\n",
        "        ('Peter',None),\n",
        "        ('Sam',{})]\n",
        "\n",
        "col = ['name','favorites']"
      ],
      "metadata": {
        "id": "d3y3GGpXc4nz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=mapData, schema = col)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfM2K9j2c8qG",
        "outputId": "4df71498-9482-4983-85f2-32e96251cef6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- favorites: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+-----+--------------------+\n",
            "| name|           favorites|\n",
            "+-----+--------------------+\n",
            "|  Bob|{color -> blue, c...|\n",
            "|  Kim|{color -> NULL, c...|\n",
            "|  Lee|{color -> , cuisi...|\n",
            "|Peter|                NULL|\n",
            "|  Sam|                  {}|\n",
            "+-----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df2 = df.select(df.name,explode(df.favorites))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qneBIuGUdY6G",
        "outputId": "97c2488d-ee0c-4f1b-91a3-7c2d2c076f4e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- key: string (nullable = false)\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+----+-------+--------+\n",
            "|name|    key|   value|\n",
            "+----+-------+--------+\n",
            "| Bob|  color|    blue|\n",
            "| Bob|cuisine| Chinese|\n",
            "| Kim|  color|    NULL|\n",
            "| Kim|cuisine|  Indian|\n",
            "| Lee|  color|        |\n",
            "| Lee|cuisine|Japanese|\n",
            "+----+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import posexplode\n",
        "df2 = df.select(df.name,posexplode(df.favorites))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJGjRObnd0zM",
        "outputId": "398f64bb-9a71-4dc4-d98b-1b163da0b4e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- pos: integer (nullable = false)\n",
            " |-- key: string (nullable = false)\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+----+---+-------+--------+\n",
            "|name|pos|    key|   value|\n",
            "+----+---+-------+--------+\n",
            "| Bob|  0|  color|    blue|\n",
            "| Bob|  1|cuisine| Chinese|\n",
            "| Kim|  0|  color|    NULL|\n",
            "| Kim|  1|cuisine|  Indian|\n",
            "| Lee|  0|  color|        |\n",
            "| Lee|  1|cuisine|Japanese|\n",
            "+----+---+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode_outer\n",
        "df2 = df.select(df.name,explode_outer(df.favorites))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekC6MEFtd8R7",
        "outputId": "5f3fa660-792a-4f18-b1b4-2831d592f28e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- key: string (nullable = true)\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+-----+-------+--------+\n",
            "| name|    key|   value|\n",
            "+-----+-------+--------+\n",
            "|  Bob|  color|    blue|\n",
            "|  Bob|cuisine| Chinese|\n",
            "|  Kim|  color|    NULL|\n",
            "|  Kim|cuisine|  Indian|\n",
            "|  Lee|  color|        |\n",
            "|  Lee|cuisine|Japanese|\n",
            "|Peter|   NULL|    NULL|\n",
            "|  Sam|   NULL|    NULL|\n",
            "+-----+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import posexplode_outer\n",
        "df2 = df.select(df.name,posexplode_outer(df.favorites))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uza2hlmud_vJ",
        "outputId": "2689127f-9573-444a-da4b-16a736b67603"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- pos: integer (nullable = true)\n",
            " |-- key: string (nullable = true)\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+-----+----+-------+--------+\n",
            "| name| pos|    key|   value|\n",
            "+-----+----+-------+--------+\n",
            "|  Bob|   0|  color|    blue|\n",
            "|  Bob|   1|cuisine| Chinese|\n",
            "|  Kim|   0|  color|    NULL|\n",
            "|  Kim|   1|cuisine|  Indian|\n",
            "|  Lee|   0|  color|        |\n",
            "|  Lee|   1|cuisine|Japanese|\n",
            "|Peter|NULL|   NULL|    NULL|\n",
            "|  Sam|NULL|   NULL|    NULL|\n",
            "+-----+----+-------+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}